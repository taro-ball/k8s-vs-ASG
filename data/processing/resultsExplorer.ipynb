{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import HTML, display\n",
    "import ipywidgets as widgets\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#print(Path.cwd().parent.parent.parent)\n",
    "base_path = Path.cwd().parent.parent.parent / \"runs\"\n",
    "#img_path = Path.cwd() / \"img.jpg\"\n",
    "# display(Image(filename=img_path))\n",
    "p = Path(base_path)\n",
    "#p.as_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c84cd886a774276a463d6d2b1cc30a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='2022.0[3-9]', description='Filter'), Checkbox(value=True, description='All'), Dropdâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tsts = [\"k8s_taewa_3lite_\",\"asg_taewa_3lite_\", \"k8s_apache_3_\", \"k8s_taewa_3_\", \"asg_apache_3_\", \"asg_taewa_3_\"]\n",
    "tsts = tsts + [\"asg_taewa_3extra_\", \"k8s_taewa_3extra_\", \"asg_raupi_3_\", \"k8s_raupi_3_\"]\n",
    "test = widgets.Dropdown(\n",
    "       options=tsts,\n",
    "       value='k8s_apache_3_',\n",
    "       description='Test:')\n",
    "all = widgets.Checkbox(value=True,\n",
    "       description='All')\n",
    "graphs=[\"QPS_estimatedProcessedBytes.png\",\"QPS_cpuUtilization.png\",\"QPS_groupInServiceCapacity.png\"]\n",
    "date_filter = widgets.Text(\n",
    "       value='2022.0[3-9]', # use glob pattern http://pymotw.com/2/glob/\n",
    "       description='Filter', )\n",
    "box = widgets.HBox([date_filter, all, test ])\n",
    "display(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pa\\OneDrive\\7.UniCode\\0thesis-code\\runs\\2022.03.26_08-14_k8s_taewa_3lite_9d2d\n",
      "[319.29463533333336]\n",
      "c:\\Users\\pa\\OneDrive\\7.UniCode\\0thesis-code\\runs\\2022.03.27_09-43_k8s_taewa_3lite_0c47\n",
      "[319.29463533333336, 247.28095199999998]\n",
      "c:\\Users\\pa\\OneDrive\\7.UniCode\\0thesis-code\\runs\\2022.03.31_23-04_k8s_taewa_3lite_41cf\n",
      "[319.29463533333336, 247.28095199999998, 254.85185566666667]\n",
      "c:\\Users\\pa\\OneDrive\\7.UniCode\\0thesis-code\\runs\\2022.04.01_08-53_k8s_taewa_3lite_41cf\n",
      "[319.29463533333336, 247.28095199999998, 254.85185566666667, 215.226485]\n",
      "c:\\Users\\pa\\OneDrive\\7.UniCode\\0thesis-code\\runs\\2022.04.01_21-08_k8s_taewa_3lite_41cf\n",
      "[319.29463533333336, 247.28095199999998, 254.85185566666667, 215.226485, 267.379857]\n",
      "c:\\Users\\pa\\OneDrive\\7.UniCode\\0thesis-code\\runs\\2022.04.02_06-11_k8s_taewa_3lite_41cf\n",
      "[319.29463533333336, 247.28095199999998, 254.85185566666667, 215.226485, 267.379857, 309.302315]\n",
      "c:\\Users\\pa\\OneDrive\\7.UniCode\\0thesis-code\\runs\\2022.04.03_09-53_k8s_taewa_3lite_41cf\n",
      "[319.29463533333336, 247.28095199999998, 254.85185566666667, 215.226485, 267.379857, 309.302315, 289.45246033333336]\n",
      "c:\\Users\\pa\\OneDrive\\7.UniCode\\0thesis-code\\runs\\2022.04.04_03-52_k8s_taewa_3lite_41cf\n",
      "[319.29463533333336, 247.28095199999998, 254.85185566666667, 215.226485, 267.379857, 309.302315, 289.45246033333336, 301.14472433333333]\n",
      "c:\\Users\\pa\\OneDrive\\7.UniCode\\0thesis-code\\runs\\2022.04.05_08-07_k8s_taewa_3lite_41cf\n",
      "[319.29463533333336, 247.28095199999998, 254.85185566666667, 215.226485, 267.379857, 309.302315, 289.45246033333336, 301.14472433333333, 275.320272]\n",
      "c:\\Users\\pa\\OneDrive\\7.UniCode\\0thesis-code\\runs\\2022.04.05_19-47_k8s_taewa_3lite_41cf\n",
      "[319.29463533333336, 247.28095199999998, 254.85185566666667, 215.226485, 267.379857, 309.302315, 289.45246033333336, 301.14472433333333, 275.320272, 321.12871233333334]\n",
      "c:\\Users\\pa\\OneDrive\\7.UniCode\\0thesis-code\\runs\\2022.05.01_20-44_k8s_taewa_3lite_41cf\n",
      "[319.29463533333336, 247.28095199999998, 254.85185566666667, 215.226485, 267.379857, 309.302315, 289.45246033333336, 301.14472433333333, 275.320272, 321.12871233333334, nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\apps\\python3.10\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "D:\\apps\\python3.10\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pa\\OneDrive\\7.UniCode\\0thesis-code\\k8s-aws-thesis\\data\\processing\\resultsExplorer.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/pa/OneDrive/7.UniCode/0thesis-code/k8s-aws-thesis/data/processing/resultsExplorer.ipynb#ch0000002?line=190'>191</a>\u001b[0m csv\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/pa/OneDrive/7.UniCode/0thesis-code/k8s-aws-thesis/data/processing/resultsExplorer.ipynb#ch0000002?line=191'>192</a>\u001b[0m csv\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mtst\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mcount\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mtst\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mtst\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/pa/OneDrive/7.UniCode/0thesis-code/k8s-aws-thesis/data/processing/resultsExplorer.ipynb#ch0000002?line=192'>193</a>\u001b[0m csv\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mint\u001b[39m,avg_duration_list))\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mmax\u001b[39m(avg_duration_list)\u001b[39m:\u001b[39;00m\u001b[39m.0f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mmean(avg_duration_list)\u001b[39m:\u001b[39;00m\u001b[39m.0f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mmin\u001b[39m(avg_duration_list)\u001b[39m:\u001b[39;00m\u001b[39m.0f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/pa/OneDrive/7.UniCode/0thesis-code/k8s-aws-thesis/data/processing/resultsExplorer.ipynb#ch0000002?line=193'>194</a>\u001b[0m csv\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mint\u001b[39m,avg_qps_list))\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mmax\u001b[39m(avg_qps_list)\u001b[39m:\u001b[39;00m\u001b[39m.0f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mmean(avg_qps_list)\u001b[39m:\u001b[39;00m\u001b[39m.0f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mmin\u001b[39m(avg_qps_list)\u001b[39m:\u001b[39;00m\u001b[39m.0f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/pa/OneDrive/7.UniCode/0thesis-code/k8s-aws-thesis/data/processing/resultsExplorer.ipynb#ch0000002?line=194'>195</a>\u001b[0m csv\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mint\u001b[39m,avg_cpu_list))\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mmax\u001b[39m(avg_cpu_list)\u001b[39m:\u001b[39;00m\u001b[39m.0f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mmean(avg_cpu_list)\u001b[39m:\u001b[39;00m\u001b[39m.0f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mmin\u001b[39m(avg_cpu_list)\u001b[39m:\u001b[39;00m\u001b[39m.0f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "#print(test._options_values)\n",
    "tests=[]\n",
    "if all.value:\n",
    "    tests=test._options_values;\n",
    "else:\n",
    "    tests.append(test.value)\n",
    "\n",
    "for tst in tests:\n",
    "    search=f'*{date_filter.value}*{tst}*'\n",
    "    nw = datetime.datetime.now()\n",
    "    count=0\n",
    "    iList=[]\n",
    "    avg_qps_list=[]\n",
    "    avg_cpu_list=[]\n",
    "    avg_duration_list=[]\n",
    "    total_err_list=[]\n",
    "\n",
    "    for i in p.glob(search):\n",
    "        print(i)\n",
    "        count+=1\n",
    "        dir = i.name\n",
    "        if not (i/\"csv\").exists():\n",
    "            line = f\"<tr><td rowspan='1'><b>skip skip skip: {dir}</b></td></tr>\"\n",
    "            iList.append(line)\n",
    "            continue\n",
    "        ##================ get json Fortio data ================\n",
    "        #print(i)\n",
    "        json_paths = (i/\"csv\").glob('*.json')\n",
    "        fortio_path=list(json_paths)[0]\n",
    "\n",
    "        df = pd.read_json(fortio_path, lines=True)\n",
    "        df['StartTime'] = pd.to_datetime(df['StartTime'])\n",
    "        df.set_index(['StartTime'],inplace=True)\n",
    "\n",
    "        #qps= df[[\"ActualQPS\",\"NumThreads\"]]\n",
    "        #mydf = df[df['Labels'] == 'k8s_apache_3-performance-1']\n",
    "\n",
    "        # get performance QPS\n",
    "        perf_df = df[df['Labels'].str.contains('performance-[1-3]', regex=True)]\n",
    "        #perf_data=perf_df.ActualQPS\n",
    "        #qps_lst=list(map(int,perf_data))\n",
    "        qps_lst=list(perf_df.ActualQPS)\n",
    "        avg_qps=np.mean(qps_lst)\n",
    "        avg_qps_list.append(avg_qps)\n",
    "\n",
    "        # get scaling start times\n",
    "        scaling_starts_df = df[df['Labels'].str.contains('scaling-.-1$', regex=True)]\n",
    "        #print(df)\n",
    "        #print(scaling_df['Labels'])\n",
    "\n",
    "        aws_metric0=\"backendConnectionErrors\"\n",
    "        c_path_err=list((i/\"csv\").glob('*'+aws_metric0+'.csv'))[0]\n",
    "        err_df = pd.read_csv(c_path_err, parse_dates=['datetime'], index_col=\"datetime\")\n",
    "\n",
    "        ## ================ PERFORMANCE CloudWatch data ================\n",
    "        aws_metric1=\"cpuUtilization\"\n",
    "        csv_paths = (i/\"csv\").glob('*'+aws_metric1+'.csv')\n",
    "        c_path=list(csv_paths)[0]\n",
    "        mdf = pd.read_csv(c_path, parse_dates=['datetime'], index_col=\"datetime\")\n",
    "        perfomance_cpu_list=[]\n",
    "        #print(c_path)\n",
    "        for index,value in perf_df.iterrows():\n",
    "            perf_start=index#pd.to_datetime(stime)\n",
    "            #print(perf_start)\n",
    "            \n",
    "            # get 4 max:\n",
    "            # mmdf=mdf[perf_start:perf_start+ pd.Timedelta(5, \"m\")]\n",
    "            # mmmdf=mmdf.nlargest(4, aws_metric1).sort_index()\n",
    "            # get 3 mid:\n",
    "            \n",
    "            mmmdf=mdf[perf_start+ pd.Timedelta(1, \"m\"):perf_start + pd.Timedelta(4, \"m\")]\n",
    "            cpu_list=list(mmmdf[aws_metric1])\n",
    "            average_cpu=np.mean(cpu_list)\n",
    "            perfomance_cpu_list.append(average_cpu)\n",
    "\n",
    "            #print(list(mmmdf.cpuUtilization))\n",
    "            if value.Labels[-1] == '1':\n",
    "                first_perf_start=index\n",
    "                #print(value.Labels)\n",
    "\n",
    "        # get number of errors from the start of first performance till the end of last scaling\n",
    "        merr_df=err_df[first_perf_start:first_perf_start + pd.Timedelta(68, \"m\")] \n",
    "        err_list=list(merr_df[aws_metric0])\n",
    "        total_err_list.append(sum(err_list))\n",
    "        #print(total_err_list)\n",
    "\n",
    "        avg_cpu=np.mean(perfomance_cpu_list)\n",
    "        avg_cpu_list.append(avg_cpu)\n",
    "\n",
    "        ## ================ SCALING CloudWatch data ================\n",
    "        aws_metric2=\"groupInServiceCapacity\"\n",
    "        scaling_durations=[]\n",
    "        csv_paths2 = (i/\"csv\").glob('*'+aws_metric2+'.csv')\n",
    "        c_path2=list(csv_paths2)[0]\n",
    "        cwdf2 = pd.read_csv(c_path2, parse_dates=['datetime'], index_col=\"datetime\")\n",
    "        #print(c_path2)\n",
    "        for index,value in scaling_starts_df.iterrows():\n",
    "            scale_start=index\n",
    "            #print(scale_start)\n",
    "            \n",
    "            ccwdf2=cwdf2[scale_start:scale_start+ pd.Timedelta(14, \"m\")] # only need to look 14 min ahead as it's the length of the scaling run\n",
    "            max_scaled=ccwdf2[ccwdf2[aws_metric2].ge(3)] #.index[0]\n",
    "\n",
    "            # print(ccwdf2.head(6))\n",
    "            # print(max_scaled.head(2))\n",
    "\n",
    "            if max_scaled.size > 0:\n",
    "                cw_reach_max_time=max_scaled.index[0]\n",
    "                duration = cw_reach_max_time - index\n",
    "                duration_in_s = duration.total_seconds()\n",
    "                #minutes = divmod(duration_in_s, 60)[0]\n",
    "                #print(reach_max_time)\n",
    "                #s = scaling_starts_df.index.get_loc(cw_reach_max_time, method='nearest')\n",
    "                #max_minute=scaling_starts_df[reach_max_time]\n",
    "                \n",
    "                # print(index)\n",
    "                # print(cw_reach_max_time)\n",
    "                scaling_durations.append(duration_in_s)\n",
    "            else:\n",
    "                duration_in_s = 0\n",
    "        avg_duration=np.mean(scaling_durations)\n",
    "        \n",
    "        if np.isnan(avg_duration): avg_duration=0\n",
    "        avg_duration_list.append(avg_duration)\n",
    "\n",
    "        ##================ generate rows ================\n",
    "        print(avg_duration_list)\n",
    "        line = \"\"\n",
    "        line = f\"\"\"<tr><td rowspan='1'>{count}:  <a href='{i.name}'>{dir}</a> </td><td>column2</td><td>column3</td>\n",
    "                <td>Dura-tion s</td><td>QPS</td><td>CPU %</td>\n",
    "                <td>Err</td>\n",
    "                </tr><tr>\"\"\"\n",
    "        ####====== Images\n",
    "        for y in graphs:\n",
    "            #print(i.name)\n",
    "            img=f'{i.name}/csv/{y}'\n",
    "            line+=f\"<td><img alt='{y}' src='{img}' /></td>\"\n",
    "\n",
    "        ####====== Data\n",
    "\n",
    "        #data=str(lst)[1:-1].replace(\", \", \"<br>\")\n",
    "        line+=f\"<td>{list(map(int,scaling_durations))}<br><b>{avg_duration:.0f}</b></td>\"\n",
    "        line+=f\"<td>{list(map(int,qps_lst))}<br><b>{avg_qps:.0f}</td>\"\n",
    "        line+=f\"<td>{list(map(int,perfomance_cpu_list))}<br><b>{avg_cpu:.0f}</b></td>\"\n",
    "        line+=f\"<td><b>{total_err_list[-1]}</b></td>\"\n",
    "\n",
    "        line+=\"</tr>\"\n",
    "        #line+=\"</tr><tr><td rowspan='1'>~~~</td></tr>\"\n",
    "        iList.append(line)\n",
    "    \n",
    "    total=f\"\"\"<td></td><td></td><td></td>\n",
    "        <td>max:<br>{max(avg_duration_list):.0f}<br>min:<br>{min(avg_duration_list):.0f}<br>mean:<br>{np.mean(avg_duration_list):.0f}<br></td>\n",
    "        <td>max:<br>{max(avg_qps_list):.0f}<br>min:<br>{min(avg_qps_list):.0f}<br>mean:<br>{np.mean(avg_qps_list):.0f}<br></td>\n",
    "        <td>max:<br>{max(avg_cpu_list):.0f}<br>min:<br>{min(avg_cpu_list):.0f}<br>mean:<br>{np.mean(avg_cpu_list):.0f}<br></td>\n",
    "        <td>max:<br>{max(total_err_list):.0f}<br>min:<br>{min(total_err_list):.0f}<br>mean:<br>{np.mean(total_err_list):.0f}<br></td>\"\"\"\n",
    "    iList.append(total)\n",
    "    iList.insert(0,total)\n",
    "    imagesList = ''.join(iList)\n",
    "\n",
    "    ##================ save HTML ================\n",
    "\n",
    "    html_path=p/f'o_{tst}.html'\n",
    "    header=f\"<head><title>{tst}</title>\"\n",
    "    header+=\"<style>table, th, td {border: 1px solid black;font-size: 20px;} body {font: 20px Arial, sans-serif;}</style></head>\"\n",
    "    header+=f\"date: {nw}<br><h2>{tst} ({count})</h2><br>\"\n",
    "\n",
    "    ##================ generate menu\n",
    "    def sorter(item):\n",
    "        \"\"\"sort by app and nodes\"\"\"\n",
    "        x = ''.join(item.name.split(\"_\")[2:4])\n",
    "        return x\n",
    "    header+=\"<table><tr>\"\n",
    "    files = sorted(p.glob('*.html'), key=sorter)\n",
    "    for h in files:\n",
    "        test_name=h.name\n",
    "        if h.name.find(f'{tst}')>0:\n",
    "            test_name=f\"<b>{test_name}</b>\"\n",
    "        if (files.index(h)% 2) == 0:\n",
    "            header+=f\"<td><a href='{test_name}'>{test_name}</a>&nbsp;\"\n",
    "        else:\n",
    "            header+=f\"<br><a href='{test_name}'>{test_name}</a>&nbsp;</td>\"\n",
    "        \n",
    "    header+=\"</tr></table>\"\n",
    "    header+=\"<table>\"\n",
    "    footer=\"</table>\"\n",
    "\n",
    "    page= header + imagesList\n",
    "    a = HTML(page)\n",
    "    html_src = a.data\n",
    "    with open(html_path, 'w') as f:\n",
    "        f.write(html_src)\n",
    "\n",
    "    csv=\"\"\n",
    "    csv+=f'{tst},{count},{tst.split(\"_\")[0]},{tst.split(\"_\")[1]},'\n",
    "    csv+=f'\"{list(map(int,avg_duration_list))}\",{max(avg_duration_list):.0f},{np.mean(avg_duration_list):.0f},{min(avg_duration_list):.0f},'\n",
    "    csv+=f'\"{list(map(int,avg_qps_list))}\",{max(avg_qps_list):.0f},{np.mean(avg_qps_list):.0f},{min(avg_qps_list):.0f},'\n",
    "    csv+=f'\"{list(map(int,avg_cpu_list))}\",{max(avg_cpu_list):.0f},{np.mean(avg_cpu_list):.0f},{min(avg_cpu_list):.0f},'\n",
    "    csv+=f'\"{total_err_list}\",{max(total_err_list):.0f},{np.mean(total_err_list):.0f},{min(total_err_list):.0f}\\n'\n",
    "\n",
    "    csv_path=p/f'o_summary.csv'\n",
    "    with open(csv_path, \"a\") as csvfile:\n",
    "        csvfile.write(csv)\n",
    "\n",
    "    #display(a, metadata=dict(isolated=True))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25b7e89b1537daa2118c7b94597c9101415ef6880ba8947cb00ebe6160bb5a7f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
